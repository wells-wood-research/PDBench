{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import heapq\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import kmtools.sci_tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import proteinsolver\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "import torch_geometric\n",
    "#from IPython.display import HTML, display\n",
    "from kmbio import PDB\n",
    "from torch_geometric.data import Batch\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "acids = [\n",
    "    \"A\",\n",
    "    \"C\",\n",
    "    \"D\",\n",
    "    \"E\",\n",
    "    \"F\",\n",
    "    \"G\",\n",
    "    \"H\",\n",
    "    \"I\",\n",
    "    \"K\",\n",
    "    \"L\",\n",
    "    \"M\",\n",
    "    \"N\",\n",
    "    \"P\",\n",
    "    \"Q\",\n",
    "    \"R\",\n",
    "    \"S\",\n",
    "    \"T\",\n",
    "    \"V\",\n",
    "    \"W\",\n",
    "    \"Y\",\n",
    "]\n",
    "\n",
    "@torch.no_grad()\n",
    "def design_sequence(net, data, random_position=False, value_selection_strategy=\"map\", num_categories=None):\n",
    "    assert value_selection_strategy in (\"map\", \"multinomial\", \"ref\")\n",
    "\n",
    "    if num_categories is None:\n",
    "        num_categories = data.x.max().item()\n",
    "\n",
    "    if hasattr(data, \"batch\"):\n",
    "        batch_size = data.batch.max().item() + 1\n",
    "    else:\n",
    "        print(\"Defaulting to batch size of one.\")\n",
    "        batch_size = 1\n",
    "\n",
    "    if value_selection_strategy == \"ref\":\n",
    "        x_ref = data.y if hasattr(data, \"y\") and data.y is not None else data.x\n",
    "\n",
    "    x = torch.ones_like(data.x) * num_categories\n",
    "    x_proba = torch.zeros_like(x).to(torch.float)\n",
    "    index_array_ref = torch.arange(x.size(0))\n",
    "    mask_ref = x == num_categories\n",
    "    while mask_ref.any():\n",
    "        output = net(x, data.edge_index, data.edge_attr)\n",
    "        output_proba_ref = torch.softmax(output, dim=1)\n",
    "        output_proba_max_ref, _ = output_proba_ref.max(dim=1)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            mask = mask_ref\n",
    "            if batch_size > 1:\n",
    "                mask = mask & (data.batch == i)\n",
    "\n",
    "            index_array = index_array_ref[mask]\n",
    "            max_probas = output_proba_max_ref[mask]\n",
    "\n",
    "            if random_position:\n",
    "                selected_residue_subindex = torch.randint(0, max_probas.size(0), (1,)).item()\n",
    "                max_proba_index = index_array[selected_residue_subindex]\n",
    "            else:\n",
    "                selected_residue_subindex = max_probas.argmax().item()\n",
    "                max_proba_index = index_array[selected_residue_subindex]\n",
    "\n",
    "            assert x[max_proba_index] == num_categories\n",
    "            assert x_proba[max_proba_index] == 0\n",
    "            category_probas = output_proba_ref[max_proba_index]\n",
    "\n",
    "            if value_selection_strategy == \"map\":\n",
    "                chosen_category_proba, chosen_category = category_probas.max(dim=0)\n",
    "            elif value_selection_strategy == \"multinomial\":\n",
    "                chosen_category = torch.multinomial(category_probas, 1).item()\n",
    "                chosen_category_proba = category_probas[chosen_category]\n",
    "            else:\n",
    "                assert value_selection_strategy == \"ref\"\n",
    "                chosen_category = x_ref[max_proba_index]\n",
    "                chosen_category_proba = category_probas[chosen_category]\n",
    "\n",
    "            assert chosen_category != num_categories\n",
    "            x[max_proba_index] = chosen_category\n",
    "            x_proba[max_proba_index] = chosen_category_proba\n",
    "        mask_ref = x == num_categories\n",
    "        del output, output_proba_ref, output_proba_max_ref\n",
    "    return x.cpu(), x_proba.cpu()\n",
    "    \n",
    "\n",
    "def run_ps(path_to_assemblies:Path, dataset_list:Path):\n",
    "    #load the model\n",
    "    state_file = '/home/s1706179/Proteinsolver/e53-s1952148-d93703104.state'\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    %run /home/s1706179/Proteinsolver/model.py\n",
    "\n",
    "    batch_size = 512\n",
    "    num_features = 20\n",
    "    adj_input_size = 2\n",
    "    hidden_size = 128\n",
    "    frac_present = 0.5\n",
    "    frac_present_valid = frac_present\n",
    "    info_size= 1024\n",
    "\n",
    "    net = Net(\n",
    "        x_input_size=num_features + 1, adj_input_size=adj_input_size, hidden_size=hidden_size, output_size=num_features\n",
    "    )\n",
    "    net.load_state_dict(torch.load(state_file, map_location=device))\n",
    "    net.eval()\n",
    "    net = net.to(device)\n",
    "    #run predictions\n",
    "    with open(dataset_list,'r') as file:\n",
    "        structures = [x.strip(\"\\n\") for x in file.readlines()]\n",
    "    results={}\n",
    "    for protein in structures:\n",
    "        STRUCTURE_FILE = path_to_assemblies/(protein[:4]+'.pdb')\n",
    "        chain_id=protein[-1]\n",
    "        try:\n",
    "            structure_all = PDB.load(STRUCTURE_FILE)\n",
    "            structure = PDB.Structure(STRUCTURE_FILE.name + chain_id, structure_all[0].extract(chain_id))\n",
    "            pdata = proteinsolver.utils.extract_seq_and_adj(structure, chain_id)\n",
    "            data = proteinsolver.datasets.protein.row_to_data(pdata)\n",
    "            data = proteinsolver.datasets.protein.transform_edge_attr(data)\n",
    "            residues, residue_probas = design_sequence(\n",
    "                net, data.to(device), random_position=False, value_selection_strategy=\"map\", num_categories=20\n",
    "            )\n",
    "            results[protein] = \"\".join(proteinsolver.utils.AMINO_ACIDS[i] for i in residues)\n",
    "        except ValueError:\n",
    "            continue\n",
    "            \n",
    "\n",
    "    enc=OneHotEncoder(categories=[acids],sparse=False)\n",
    "    predicted_sequences = []\n",
    "    with open('/home/s1706179/Proteinsolver/proteinsolver_nmr.txt','w') as file:\n",
    "        file.write(f\"ignore_uncommon False\\ninclude_pdbs\\n##########\\n\")\n",
    "        for chain in results:\n",
    "            predicted_sequences+=list(results[chain])\n",
    "            file.write(f\"{chain} {len(results[chain])}\\n\")\n",
    "    arr=enc.fit_transform(np.array(predicted_sequences).reshape(-1, 1))\n",
    "    pd.DataFrame(arr).to_csv(\"/home/s1706179/Proteinsolver/proteinsolver_nmr.csv\", header=None, index=None)\n",
    "    \n",
    "run_ps(Path(\"/home/s1706179/Rosetta/empty_nmr_backbones/\"),Path(\"/home/s1706179/Rosetta/data/nmr_set.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
